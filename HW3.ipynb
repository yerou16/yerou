{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4a3c02e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "批踢踢實業坊\n",
      "/bbs/\n",
      "看板 KoreaStar\n",
      "/bbs/KoreaStar/index.html\n",
      "關於我們\n",
      "/about.html\n",
      "聯絡資訊\n",
      "/contact.html\n",
      "看板\n",
      "/bbs/KoreaStar/index.html\n",
      "精華區\n",
      "/man/KoreaStar/index.html\n",
      "最舊\n",
      "/bbs/KoreaStar/index1.html\n",
      "‹ 上頁\n",
      "/bbs/KoreaStar/index2438.html\n",
      "下頁 ›\n",
      "None\n",
      "最新\n",
      "/bbs/KoreaStar/index.html\n",
      "[閒聊] 【GD事件相關熱門整理】\n",
      "/bbs/KoreaStar/M.1698237942.A.BCD.html\n",
      "搜尋同標題文章\n",
      "/bbs/KoreaStar/search?q=thread%3A%5B%E9%96%92%E8%81%8A%5D+%E3%80%90GD%E4%BA%8B%E4%BB%B6%E7%9B%B8%E9%97%9C%E7%86%B1%E9%96%80%E6%95%B4%E7%90%86%E3%80%91\n",
      "搜尋看板內 Master5566 的文章\n",
      "/bbs/KoreaStar/search?q=author%3AMaster5566\n",
      "[閒聊] 2024 SM SEASON'S GREETINGS沒有出EXO的\n",
      "/bbs/KoreaStar/M.1698238172.A.F9E.html\n",
      "搜尋同標題文章\n",
      "/bbs/KoreaStar/search?q=thread%3A%5B%E9%96%92%E8%81%8A%5D+2024+SM+SEASON%27S+GREETINGS%E6%B2%92%E6%9C%89%E5%87%BAEXO%E7%9A%84\n",
      "搜尋看板內 bboy0223 的文章\n",
      "/bbs/KoreaStar/search?q=author%3Abboy0223\n",
      "[情報] GD吸毒，與李善均是兩碼子事\n",
      "/bbs/KoreaStar/M.1698238993.A.09E.html\n",
      "搜尋同標題文章\n",
      "/bbs/KoreaStar/search?q=thread%3A%5B%E6%83%85%E5%A0%B1%5D+GD%E5%90%B8%E6%AF%92%EF%BC%8C%E8%88%87%E6%9D%8E%E5%96%84%E5%9D%87%E6%98%AF%E5%85%A9%E7%A2%BC%E5%AD%90%E4%BA%8B\n",
      "搜尋看板內 kadar 的文章\n",
      "/bbs/KoreaStar/search?q=author%3Akadar\n",
      "[情報] 李泳知將參演火球祭\n",
      "/bbs/KoreaStar/M.1698240729.A.85A.html\n",
      "搜尋同標題文章\n",
      "/bbs/KoreaStar/search?q=thread%3A%5B%E6%83%85%E5%A0%B1%5D+%E6%9D%8E%E6%B3%B3%E7%9F%A5%E5%B0%87%E5%8F%83%E6%BC%94%E7%81%AB%E7%90%83%E7%A5%AD\n",
      "搜尋看板內 drinkjuice 的文章\n",
      "/bbs/KoreaStar/search?q=author%3Adrinkjuice\n",
      "[閒聊] 從來沒上過Music Bank的韓國TOP女團\n",
      "/bbs/KoreaStar/M.1698244725.A.78B.html\n",
      "搜尋同標題文章\n",
      "/bbs/KoreaStar/search?q=thread%3A%5B%E9%96%92%E8%81%8A%5D+%E5%BE%9E%E4%BE%86%E6%B2%92%E4%B8%8A%E9%81%8EMusic+Bank%E7%9A%84%E9%9F%93%E5%9C%8BTOP%E5%A5%B3%E5%9C%98\n",
      "搜尋看板內 XOD 的文章\n",
      "/bbs/KoreaStar/search?q=author%3AXOD\n",
      "[閒聊] 讓人想到裴勇浚的男偶像的出國照\n",
      "/bbs/KoreaStar/M.1698249073.A.17F.html\n",
      "搜尋同標題文章\n",
      "/bbs/KoreaStar/search?q=thread%3A%5B%E9%96%92%E8%81%8A%5D+%E8%AE%93%E4%BA%BA%E6%83%B3%E5%88%B0%E8%A3%B4%E5%8B%87%E6%B5%9A%E7%9A%84%E7%94%B7%E5%81%B6%E5%83%8F%E7%9A%84%E5%87%BA%E5%9C%8B%E7%85%A7\n",
      "搜尋看板內 Master5566 的文章\n",
      "/bbs/KoreaStar/search?q=author%3AMaster5566\n",
      "[閒聊] 在娛樂圈留下美好先例的偶像\n",
      "/bbs/KoreaStar/M.1698249576.A.4E2.html\n",
      "搜尋同標題文章\n",
      "/bbs/KoreaStar/search?q=thread%3A%5B%E9%96%92%E8%81%8A%5D+%E5%9C%A8%E5%A8%9B%E6%A8%82%E5%9C%88%E7%95%99%E4%B8%8B%E7%BE%8E%E5%A5%BD%E5%85%88%E4%BE%8B%E7%9A%84%E5%81%B6%E5%83%8F\n",
      "搜尋看板內 XOD 的文章\n",
      "/bbs/KoreaStar/search?q=author%3AXOD\n",
      "[心得] 金世正妹妹現場表演心得\n",
      "/bbs/KoreaStar/M.1698255918.A.CE1.html\n",
      "搜尋同標題文章\n",
      "/bbs/KoreaStar/search?q=thread%3A%5B%E5%BF%83%E5%BE%97%5D+%E9%87%91%E4%B8%96%E6%AD%A3%E5%A6%B9%E5%A6%B9%E7%8F%BE%E5%A0%B4%E8%A1%A8%E6%BC%94%E5%BF%83%E5%BE%97\n",
      "搜尋看板內 Giorno7777 的文章\n",
      "/bbs/KoreaStar/search?q=author%3AGiorno7777\n",
      "[新聞] 與六千觀眾合作…MAMAMOO+臺灣首場演唱會\n",
      "/bbs/KoreaStar/M.1698256051.A.4E1.html\n",
      "搜尋同標題文章\n",
      "/bbs/KoreaStar/search?q=thread%3A%5B%E6%96%B0%E8%81%9E%5D+%E8%88%87%E5%85%AD%E5%8D%83%E8%A7%80%E7%9C%BE%E5%90%88%E4%BD%9C%E2%80%A6MAMAMOO%2B%E8%87%BA%E7%81%A3%E9%A6%96%E5%A0%B4%E6%BC%94%E5%94%B1%E6%9C%83\n",
      "搜尋看板內 kadar 的文章\n",
      "/bbs/KoreaStar/search?q=author%3Akadar\n",
      "[新聞] GD染毒是「江南夜店29歲女室長」爆出來的\n",
      "/bbs/KoreaStar/M.1698282444.A.25B.html\n",
      "搜尋同標題文章\n",
      "/bbs/KoreaStar/search?q=thread%3A%5B%E6%96%B0%E8%81%9E%5D+GD%E6%9F%93%E6%AF%92%E6%98%AF%E3%80%8C%E6%B1%9F%E5%8D%97%E5%A4%9C%E5%BA%9729%E6%AD%B2%E5%A5%B3%E5%AE%A4%E9%95%B7%E3%80%8D%E7%88%86%E5%87%BA%E4%BE%86%E7%9A%84\n",
      "搜尋看板內 joanzkow 的文章\n",
      "/bbs/KoreaStar/search?q=author%3Ajoanzkow\n",
      "[情報] 2023年08-10月 來台活動/售票資訊\n",
      "/bbs/KoreaStar/M.1691286310.A.A1C.html\n",
      "搜尋同標題文章\n",
      "/bbs/KoreaStar/search?q=thread%3A%5B%E6%83%85%E5%A0%B1%5D+2023%E5%B9%B408-10%E6%9C%88+%E4%BE%86%E5%8F%B0%E6%B4%BB%E5%8B%95%2F%E5%94%AE%E7%A5%A8%E8%B3%87%E8%A8%8A\n",
      "搜尋看板內 elvissu 的文章\n",
      "/bbs/KoreaStar/search?q=author%3Aelvissu\n",
      "[公告] 韓星板板規\n",
      "/bbs/KoreaStar/M.1693884697.A.D5A.html\n",
      "搜尋同標題文章\n",
      "/bbs/KoreaStar/search?q=thread%3A%5B%E5%85%AC%E5%91%8A%5D+%E9%9F%93%E6%98%9F%E6%9D%BF%E6%9D%BF%E8%A6%8F\n",
      "搜尋看板內 yoche2000 的文章\n",
      "/bbs/KoreaStar/search?q=author%3Ayoche2000\n",
      "[情報] 2023年10-11月 回歸&出道團體/歌手\n",
      "/bbs/KoreaStar/M.1696005374.A.CCB.html\n",
      "搜尋同標題文章\n",
      "/bbs/KoreaStar/search?q=thread%3A%5B%E6%83%85%E5%A0%B1%5D+2023%E5%B9%B410-11%E6%9C%88+%E5%9B%9E%E6%AD%B8%26%E5%87%BA%E9%81%93%E5%9C%98%E9%AB%94%2F%E6%AD%8C%E6%89%8B\n",
      "搜尋看板內 yutan0802 的文章\n",
      "/bbs/KoreaStar/search?q=author%3Ayutan0802\n",
      "[公告] 置底檢舉區 (2310~2312)\n",
      "/bbs/KoreaStar/M.1696281731.A.3DD.html\n",
      "搜尋同標題文章\n",
      "/bbs/KoreaStar/search?q=thread%3A%5B%E5%85%AC%E5%91%8A%5D+%E7%BD%AE%E5%BA%95%E6%AA%A2%E8%88%89%E5%8D%80+%282310~2312%29\n",
      "搜尋看板內 yoche2000 的文章\n",
      "/bbs/KoreaStar/search?q=author%3Ayoche2000\n",
      "[閒聊] 韓星板 2023年十月 置底閒聊文\n",
      "/bbs/KoreaStar/M.1696281892.A.691.html\n",
      "搜尋同標題文章\n",
      "/bbs/KoreaStar/search?q=thread%3A%5B%E9%96%92%E8%81%8A%5D+%E9%9F%93%E6%98%9F%E6%9D%BF+2023%E5%B9%B4%E5%8D%81%E6%9C%88+%E7%BD%AE%E5%BA%95%E9%96%92%E8%81%8A%E6%96%87\n",
      "搜尋看板內 yoche2000 的文章\n",
      "/bbs/KoreaStar/search?q=author%3Ayoche2000\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# 設定要爬取的網址\n",
    "url = 'https://www.ptt.cc/bbs/KoreaStar/index.html'\n",
    "\n",
    "# 發送HTTP請求並取得網頁內容\n",
    "response = requests.get(url)\n",
    "\n",
    "# 檢查是否成功取得網頁內容\n",
    "if response.status_code == 200:\n",
    "    # 解析HTML內容\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    # 找到標題和連結\n",
    "    titles = soup.find_all('a')  # 假設連結是用<a>標籤表示的\n",
    "    for title in titles:\n",
    "        print(title.text)  # 標題文字\n",
    "        link = title.get('href')  # 使用get方法來獲取'href'屬性\n",
    "        print(link) \n",
    "else:\n",
    "    print('無法取得網頁內容，HTTP錯誤碼：', response.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9bb9240d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ": 推俊昊 見面會真的誠意滿滿\n",
      ": 推，滿滿的3小時，非常有誠意\n",
      ": 推俊昊，真的滿滿三小時，八首歌表演+\n",
      ": 舞群，超級精彩的。\n",
      ": 誠意滿滿的3小時 示範噴香水和給粉絲吃剩\n",
      ": 的嗨啾 對視眨眼一直輸給粉絲XD\n",
      ": 推俊昊\n",
      ": 俊昊必推，溫暖又可愛超寵粉\n",
      ": 俊昊推！當天去真的超值，整整3小時熱舞又\n",
      ": 唱歌，好有魅力\n",
      ": 推推 非常有誠意\n",
      ": 推俊昊3小時滿滿的誠意！真的超棒！\n",
      ": 超好看真的感受到俊昊滿滿的愛TT\n",
      ": 頭場真的好幸福，已羨慕\n",
      ": 推推 很開心帶給俊昊滿滿的感動也帶\n",
      ": 給自己滿滿的幸福\n",
      ": 推俊昊！見面會超用心超有誠意 度過超幸\n",
      ": 福的三小時\n",
      ": 理想苟\n",
      ": 推俊昊，見面會真的誠意滿滿超用心！超\n",
      ": 感動，有去現場真的是太好了\n",
      ": 還好堅持要去看，真的是寵粉寵上天的俊昊\n",
      ": 啊......\n",
      ": 超感動誠意滿滿的三小時！看完只能廢\n",
      ": 人症，俊昊真的好溫柔寵粉～\n",
      ": 推俊昊 期待下次來台的活動\n",
      ": 俊昊可愛又寵粉，舞台超帥，希望下次是整\n",
      ": 團一起來！\n",
      ": 俊昊真的好帥聲音又溫柔，有去真是太幸\n",
      ": 福了～\n",
      ": 廢人症超嚴重…..\n",
      ": 到今天還在廢人症+1\n",
      ": 我真的一邊合唱一邊落淚TT也很感謝聯應\n",
      ": 準備這麽溫柔的應援嗚嗚嗚\n",
      ": 推俊昊，誠意滿滿的3小時，敬業又認真\n",
      ": 的態度，感動！\n",
      ": 推誠意滿滿的俊昊 感受到好多好多的愛和\n",
      ": 幸福 謝謝俊昊\n",
      ": 這場真的很有誠意，跳女團的舞很好看！\n",
      ": 如果可以唱的真好，可惜只有一小段啊\n",
      ": 俊昊的見面會很用心 推推\n",
      ": 超寵粉\n",
      ": 只能說，在現場的我內心充滿激動，三個小\n",
      ": 時既充實又滿足，謝謝俊昊帶給我的幸福和力\n",
      ": 量，雖然還在廢人症+1中 XD\n",
      ": 超有誠意，希望下次是演唱會\n",
      ": FM根本直接升級成Fancon！出乎意料的超過\n",
      ": 三小時，誠意很滿的內容！北流的音響跟燈\n",
      ": 光效果很好！謝謝俊昊給了個幸福的回憶！\n",
      ": 因為俊昊，我們都很幸福\n",
      ": 回來推 已經一週了還沒走出來\n",
      ": 越陷越深了......\n",
      "\n",
      "\n",
      "已爬取 20 篇相关文章。\n",
      "数据已保存到 comments.json\n",
      "[': 推俊昊 見面會真的誠意滿滿', ': 推，滿滿的3小時，非常有誠意', ': 推俊昊，真的滿滿三小時，八首歌表演+', ': 舞群，超級精彩的。', ': 誠意滿滿的3小時 示範噴香水和給粉絲吃剩', ': 的嗨啾 對視眨眼一直輸給粉絲XD', ': 推俊昊', ': 俊昊必推，溫暖又可愛超寵粉', ': 俊昊推！當天去真的超值，整整3小時熱舞又', ': 唱歌，好有魅力', ': 推推 非常有誠意', ': 推俊昊3小時滿滿的誠意！真的超棒！', ': 超好看真的感受到俊昊滿滿的愛TT', ': 頭場真的好幸福，已羨慕', ': 推推 很開心帶給俊昊滿滿的感動也帶', ': 給自己滿滿的幸福', ': 推俊昊！見面會超用心超有誠意 度過超幸', ': 福的三小時', ': 理想苟', ': 推俊昊，見面會真的誠意滿滿超用心！超', ': 感動，有去現場真的是太好了', ': 還好堅持要去看，真的是寵粉寵上天的俊昊', ': 啊......', ': 超感動誠意滿滿的三小時！看完只能廢', ': 人症，俊昊真的好溫柔寵粉～', ': 推俊昊 期待下次來台的活動', ': 俊昊可愛又寵粉，舞台超帥，希望下次是整', ': 團一起來！', ': 俊昊真的好帥聲音又溫柔，有去真是太幸', ': 福了～', ': 廢人症超嚴重…..', ': 到今天還在廢人症+1', ': 我真的一邊合唱一邊落淚TT也很感謝聯應', ': 準備這麽溫柔的應援嗚嗚嗚', ': 推俊昊，誠意滿滿的3小時，敬業又認真', ': 的態度，感動！', ': 推誠意滿滿的俊昊 感受到好多好多的愛和', ': 幸福 謝謝俊昊', ': 這場真的很有誠意，跳女團的舞很好看！', ': 如果可以唱的真好，可惜只有一小段啊', ': 俊昊的見面會很用心 推推', ': 超寵粉', ': 只能說，在現場的我內心充滿激動，三個小', ': 時既充實又滿足，謝謝俊昊帶給我的幸福和力', ': 量，雖然還在廢人症+1中 XD', ': 超有誠意，希望下次是演唱會', ': FM根本直接升級成Fancon！出乎意料的超過', ': 三小時，誠意很滿的內容！北流的音響跟燈', ': 光效果很好！謝謝俊昊給了個幸福的回憶！', ': 因為俊昊，我們都很幸福', ': 回來推 已經一週了還沒走出來', ': 越陷越深了......']\n"
     ]
    }
   ],
   "source": [
    "#爬取關於20篇李俊昊相關的文章留言\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "\n",
    "# 要搜索的关键字\n",
    "search_keyword = '李俊昊'\n",
    "\n",
    "url = 'https://www.ptt.cc/bbs/KoreaStar/index.html'\n",
    "\n",
    "# 创建一个空列表，用于存储已经印出的留言内容\n",
    "printed_comments = []\n",
    "\n",
    "# 处理页面爬取的函数\n",
    "def scrape_page(url):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        titles = soup.find_all('div', class_='title')\n",
    "        \n",
    "        found_new_comments = 0  # 用于计数已找到的相关文章数量\n",
    "\n",
    "        for title in titles:\n",
    "            if title.a is not None:\n",
    "                title_text = title.a.text\n",
    "                link = title.a['href']\n",
    "                if search_keyword in title_text:\n",
    "                    article_url = 'https://www.ptt.cc' + link\n",
    "                    found_new_comments += 1  # 增加找到的相关文章数量\n",
    "                    scrape_comments(article_url)\n",
    "\n",
    "        # 检查是否找到上一页链接\n",
    "        prev_page_link = soup.find('a', string='‹ 上頁')\n",
    "        if not prev_page_link:\n",
    "            print(\"没有更多前一頁可爬取。\")\n",
    "            return False\n",
    "        else:\n",
    "            prev_page_href = prev_page_link.get('href')\n",
    "            prev_page_url = 'https://www.ptt.cc' + prev_page_href\n",
    "            return prev_page_url\n",
    "\n",
    "    return False\n",
    "\n",
    "# 处理留言爬取的函数\n",
    "def scrape_comments(article_url):\n",
    "    response = requests.get(article_url)\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        comments = soup.find_all('span', class_='push-content')\n",
    "        if len(comments) == 0:\n",
    "            print(\"未找到评论数据。\")\n",
    "        for comment in comments:\n",
    "            comment_text = comment.text\n",
    "            # 检查留言是否已经印出过，如果没有，才印出\n",
    "            comment_identifier = comment_text  # 将 comment_text 作为唯一标识\n",
    "            if comment_identifier not in printed_comments:\n",
    "                print(comment_text)\n",
    "                printed_comments.append(comment_identifier)  # 將留言文本添加到已印出列表中\n",
    "        print('\\n')\n",
    "\n",
    "# 设置要爬取的相关文章数目\n",
    "target_comments = 20  # 设置你希望爬取的相关文章数量\n",
    "\n",
    "found_comments = 0  # 用于跟踪已经爬取的相关文章数量\n",
    "\n",
    "while found_comments < target_comments:\n",
    "    next_page_url = scrape_page(url)\n",
    "    if not next_page_url:\n",
    "        break\n",
    "    url = next_page_url\n",
    "    found_comments += 1\n",
    "\n",
    "print(f\"已爬取 {found_comments} 篇相关文章。\")\n",
    "\n",
    "# 定义要保存为 JSON 文件的文件名\n",
    "json_file = \"comments.json\"\n",
    "\n",
    "# 将 printed_comments 列表保存为 JSON 文件\n",
    "with open(json_file, \"w\") as file:\n",
    "    json.dump(printed_comments, file)\n",
    "\n",
    "print(f\"数据已保存到 {json_file}\")\n",
    "print(printed_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2fa6c98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
